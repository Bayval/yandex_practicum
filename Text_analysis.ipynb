{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers as ppb\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Читаем csv файл, выводим данные на экран, смотрим общую информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898321\n",
      "1    0.101679\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6775156510>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency=df['toxic'].value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar', color=list('yb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей задаче наблюдается сильный дисбаланс классов целевого признака, отрицательных ответов ≈90% , положитительных ≈ 10%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения из соображений экономии ресурсов обрабатывается небольшая группа примеров, 15000 строк. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['toxic'], axis=1)\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В исследовании будем использовать модель DistilBERT, предобученную для английского языка, которая представляет собой уменьшенную версию BERT'а. Она быстрее и легче своего старшего собрата, но при этом вполне сравнима в результативности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим предобученную модели и токенизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fb364d579049d89cb5cc2ae1d971c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=442.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2ed08682fc4755a99bacb9210243e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=267967963.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем текст в номера токенов из словаря методом encode(), добавляя токен начала (101) и токен конца текста (102). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = features['text'].apply((lambda x: tokenizer.encode(x, max_length=300, \n",
    "                                                                   truncation=True, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...\n",
       "1        [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...\n",
       "2        [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...\n",
       "3        [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...\n",
       "4        [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...\n",
       "                               ...                        \n",
       "14995    [101, 1000, 2308, 2893, 2730, 1999, 1037, 4968...\n",
       "14996    [101, 2562, 2039, 1996, 2204, 2147, 1010, 1825...\n",
       "14997    [101, 1000, 4165, 2307, 1012, 1006, 2831, 1528...\n",
       "14998    [101, 1000, 7929, 1012, 1012, 1012, 11721, 102...\n",
       "14999    [101, 1000, 12943, 3490, 1058, 10640, 1029, 21...\n",
       "Name: text, Length: 15000, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим метод padding, чтобы после токенизации мы могли представить входные данные как один двумерный массив, а не как список списков (разной длины)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  101  7526  2339 ...     0     0     0]\n",
      " [  101  1040  1005 ...     0     0     0]\n",
      " [  101  4931  2158 ...     0     0     0]\n",
      " ...\n",
      " [  101  1000  4165 ...     0     0     0]\n",
      " [  101  1000  7929 ...     0     0     0]\n",
      " [  101  1000 12943 ...     0     0     0]]\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "print(padded)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь поясним модели, что нули не несут значимой информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 300)\n"
     ]
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем текст в эмбеддинги. Для этого преобразуем данные в формат тензоров(многомерных векторов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100 \n",
    "embeddings = []\n",
    "\n",
    "for i in range(padded.shape[0] // batch_size):\n",
    "    batch = torch.LongTensor(padded[batch_size * i:batch_size * (i + 1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size * i:batch_size * (i + 1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:, 0, :].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберём все эмбеддинги в матрицу признаков вызовом функции concatenate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "features = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим признаки на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы выяснили ранее в нашей выборке отрицательных ответов ≈90% , положитительных ≈ 10%.\n",
    "Нам необходмо увеличить количество положительных ответов в 9 раз для достижения баланса.\n",
    "- Разделим обучающую выборку на отрицательные и положительные объекты;\n",
    "- Скопируем несколько раз положительные объекты;\n",
    "- С учётом полученных данных создадим новую обучающую выборку;\n",
    "- Перемешаем данные: идущие друг за другом одинаковые вопросы не помогут обучению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    " \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "    features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frequency=target_upsampled.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar',color=list('yb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель для классификации алгоритмом — логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(random_state=12345, max_iter=1000)\n",
    "model_lr.fit(features_upsampled, target_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_lr.predict(features_test)\n",
    "print('Значение f1 на тестовой выборке LogisticRegression',f1_score(target_test, prediction, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение f1 на тестовой выборке LogisticRegression 0.923390134036028"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель для классификации деревом решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params_cat = {'max_depth': range(5, 15, 3)} \n",
    "model_DTC = DecisionTreeClassifier(random_state=12345)\n",
    "grid_DTC = GridSearchCV(model_RF, params_cat, cv=5)\n",
    "grid_DTC.fit(features_upsampled, target_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = grid_DTC.predict(features_test)\n",
    "print('Значение f1 на тестовой выборке RandomForestClassifier',f1_score(target_test, prediction,average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение f1 на тестовой выборке DecisionTreeClassifier на локальной машине  0.9302531897926635"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Модель для классификации алгоритмом - \"случайный лес\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params_cat = {'max_depth': range(5, 15, 3),\n",
    "             'n_estimators': range (5, 25, 5)} \n",
    "model_RF = RandomForestClassifier()\n",
    "grid_RF = GridSearchCV(model_RF, params_cat, cv=5)\n",
    "grid_RF.fit(features_upsampled, target_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_RF = grid_RF.predict(features_test)\n",
    "print('Значение f1 на тестовой выборке RandomForestClassifier',f1_score(target_test, prediction_RF,average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение f1 на тестовой выборке RandomForestClassifier 0.929242393221426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель для классификации CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "best_model = None\n",
    "best_result = 0\n",
    "for est in range(200,300,30):\n",
    "    for depth in range(3, 12, 3):\n",
    "        model_CatBoost = CatBoostClassifier(verbose=False,random_state=12345, \n",
    "                                              n_estimators=est, \n",
    "                                              max_depth=depth) \n",
    "        model_CatBoost.fit(features_upsampled,target_upsampled) \n",
    "        predicted = model_CatBoost.predict(features_test)\n",
    "        result = f1_score(target_test,predicted) \n",
    "        if result > best_result: \n",
    "            best_model = model_CatBoost \n",
    "            best_result = result \n",
    "            best_depth = depth     \n",
    "            best_est = est\n",
    "print(\"Количество деревьев наилучшей модели:\", best_est,\n",
    "      \"Максимальная глубина:\", best_depth)\n",
    "print(f1_score(target_test,best_model.predict(features_test), average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение f1 на тестовой выборке CatBoostClassifier    0.9305237658223673"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Для обучения модели способной классифицировать комментарии на позитивные и негативные была использована нейронная сеть  DistilBert(уменьшенная версию BERT'а). \n",
    "- Изначально предоставленные данные с сильным дисбалансом классов целевого признака, для исследования выбрали одинаковое количество положительных и отрицательных комментариев, для того чтобы классы были сбалансированы. \n",
    "- Так как DistilBert требует значительных вычеслительных ресурсов, значения таких параметров как количество исследуемых данных, ограничение длины токена(max_length), размер батча были снижены(batch_size), для того чтобы код мог выполняться на виртуальной машине. При выполении задачи на локальной машине параметры были выбраны. Размер выборки = 15000, max_length=300, batch_size = 100.\n",
    "- Нейронная сеть DistilBert позволила построить модель CatBoostClassifier, классифицирующую комментарии на позитивные и негативные с наилучшим значением метрики качества F1 = 0.93\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4658,
    "start_time": "2021-06-08T20:16:01.320Z"
   },
   {
    "duration": 502,
    "start_time": "2021-06-08T20:23:52.155Z"
   },
   {
    "duration": 625,
    "start_time": "2021-06-08T20:23:59.035Z"
   },
   {
    "duration": 372,
    "start_time": "2021-06-08T20:24:00.118Z"
   },
   {
    "duration": 350,
    "start_time": "2021-06-08T20:24:12.735Z"
   },
   {
    "duration": 337,
    "start_time": "2021-06-08T20:24:19.192Z"
   },
   {
    "duration": 201,
    "start_time": "2021-06-08T20:24:23.872Z"
   },
   {
    "duration": 130,
    "start_time": "2021-06-08T20:25:23.558Z"
   },
   {
    "duration": 119,
    "start_time": "2021-06-08T20:25:35.733Z"
   },
   {
    "duration": 125,
    "start_time": "2021-06-08T20:26:01.588Z"
   },
   {
    "duration": 344,
    "start_time": "2021-06-08T20:31:45.632Z"
   },
   {
    "duration": 127,
    "start_time": "2021-06-08T20:31:50.944Z"
   },
   {
    "duration": 347,
    "start_time": "2021-06-08T20:31:59.607Z"
   },
   {
    "duration": 125,
    "start_time": "2021-06-08T20:32:44.920Z"
   },
   {
    "duration": 123,
    "start_time": "2021-06-08T20:37:38.620Z"
   },
   {
    "duration": 128,
    "start_time": "2021-06-08T20:38:52.361Z"
   },
   {
    "duration": 125,
    "start_time": "2021-06-08T20:38:56.891Z"
   },
   {
    "duration": 124,
    "start_time": "2021-06-08T20:39:22.697Z"
   },
   {
    "duration": 119,
    "start_time": "2021-06-08T20:39:33.330Z"
   },
   {
    "duration": 3,
    "start_time": "2021-06-08T20:41:49.601Z"
   },
   {
    "duration": 6,
    "start_time": "2021-06-08T20:41:50.230Z"
   },
   {
    "duration": 79226,
    "start_time": "2021-06-08T20:41:57.775Z"
   },
   {
    "duration": 184,
    "start_time": "2021-06-08T20:43:27.686Z"
   },
   {
    "duration": 18398,
    "start_time": "2021-06-08T20:43:33.164Z"
   },
   {
    "duration": 6,
    "start_time": "2021-06-08T20:43:51.564Z"
   },
   {
    "duration": 544,
    "start_time": "2021-06-08T20:44:23.014Z"
   },
   {
    "duration": 21,
    "start_time": "2021-06-08T20:44:25.654Z"
   },
   {
    "duration": 197,
    "start_time": "2021-06-08T21:13:51.818Z"
   },
   {
    "duration": 189,
    "start_time": "2021-06-08T21:13:52.043Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
